{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbed95a-4ffe-4528-8e6d-08e2bcd9149f",
   "metadata": {},
   "source": [
    "# Research Agent Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12a14e-9121-4067-aa02-861b6c7b7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fa086-42ee-40a0-8e60-d392de19b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from docgen_agent.researcher import ResearcherState, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b4043-81d6-4a1b-b432-b07fb3d043a0",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Try making changes to the agent request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1ee85-8472-46be-bbe9-66a14e93c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Examples of AI agents in various industries.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ce016-b2f9-42bc-841b-5670b20a8688",
   "metadata": {},
   "source": [
    "## Ask the Agent\n",
    "\n",
    "Here, we will send your request to the agent. The agent will print log messages to let you know what it is up to. Expect this step to take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0669ee3-902c-44a0-8916-147e53a4fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ResearcherState(\n",
    "    topic=topic,\n",
    "    number_of_queries=3,\n",
    ")\n",
    "\n",
    "state = await graph.ainvoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdedc2f-164c-4ace-8f5b-cf27eefadbd2",
   "metadata": {},
   "source": [
    "## Examine the results\n",
    "\n",
    "The researcher adds the research results to the chat log so that it is available to all later steps.\n",
    "\n",
    "Let's examine our conversation with the researcher.\n",
    "\n",
    "You should see at least three messages:\n",
    "1. A message from the model requesting a tool call.\n",
    "2. A tool_call message with the raw source data.\n",
    "3. A message from the assistant, summarizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe890305-0f1c-4c8d-a918-b5d0dbbfbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in state[\"messages\"]:\n",
    "    print(\"ROLE: \", getattr(message, \"role\", \"tool_call\"))\n",
    "    print(message.content[:500] or message.additional_kwargs)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2908c3-f9f8-4cd3-b68d-fc3a56ca645c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
